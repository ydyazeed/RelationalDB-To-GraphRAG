# ğŸ¯ Complete Guide - RAG Knowledge Graph System

## ğŸ“ Project Structure

```
RelationalDB-To-GraphRAG/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ rag_api_server.py          # Main FastAPI server
â”‚   â”œâ”€â”€ schema_extractor.py         # PostgreSQL extraction
â”‚   â”œâ”€â”€ schema_to_ontology.py       # Gemini ontology generation
â”‚   â”œâ”€â”€ create_knowledge_graph.py   # Neo4j graph builder
â”‚   â”œâ”€â”€ vector_indexer.py           # FAISS vector indexing
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                  # Docker config for Render
â”‚   â””â”€â”€ .env                        # Environment variables
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx                # Main app with tabs
â”‚   â”‚   â”œâ”€â”€ App.css                # Dark theme styles
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ BuildGraph.tsx     # Build graph interface
â”‚   â”‚       â”œâ”€â”€ BuildGraph.css
â”‚   â”‚       â”œâ”€â”€ Chat.tsx           # Chat interface
â”‚   â”‚       â””â”€â”€ Chat.css
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env                       # API URL config
â”‚
â”œâ”€â”€ README.md                       # Quick start guide
â”œâ”€â”€ DEPLOYMENT.md                   # Deployment instructions
â””â”€â”€ test-local.sh                  # Local testing script
```

---

## ğŸš€ Quick Start (Local)

### 1. Backend Setup

```bash
# Install dependencies
pip3 install -r requirements.txt

# Set up environment
cat > .env << EOF
GEMINI_API_KEY=your_api_key_here
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
EOF

# Start Neo4j
docker run -d --name neo4j \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/password \
  neo4j:latest

# Start backend
python3 rag_api_server.py
```

### 2. Frontend Setup

```bash
# Go to frontend directory
cd frontend

# Install dependencies
npm install

# Set up environment
echo "REACT_APP_API_URL=http://localhost:8000" > .env

# Start frontend
npm start
```

### 3. Test Everything

```bash
# Run test script
./test-local.sh

# Open browser
open http://localhost:3000
```

---

## ğŸŒ Deployment

### Backend on Render

1. **Create Web Service**:
   - Go to https://render.com
   - New â†’ Web Service
   - Connect GitHub repo
   - Environment: Docker
   - Add env vars: `GEMINI_API_KEY`, etc.

2. **Deploy**: 
   - Click "Create Web Service"
   - Wait 5-10 minutes
   - API live at: `https://your-app.onrender.com`

### Frontend on Vercel

1. **Update Environment**:
   ```bash
   cd frontend
   echo "REACT_APP_API_URL=https://your-app.onrender.com" > .env
   ```

2. **Deploy**:
   ```bash
   npm i -g vercel
   vercel --prod
   ```
   OR use Vercel Dashboard

3. **Live**: `https://your-app.vercel.app`

Full details in [DEPLOYMENT.md](./DEPLOYMENT.md)

---

## ğŸ¨ Frontend Features

### Build Graph Tab
- **Connection String Input**: Enter PostgreSQL connection
- **Build Button**: Start graph build process
- **Live Progress**: Real-time status updates
- **Success Message**: Confirmation when ready

### Chat Tab
- **Query Input**: Ask questions in natural language
- **AI Responses**: Formatted with markdown
- **Tool Tracking**: See which tools AI used
- **Reasoning Chain**: View AI's thought process
- **Sources**: See data sources used
- **Example Queries**: Quick-start suggestions

### UI Features
- ğŸŒ‘ Dark theme
- âš¡ Real-time updates
- ğŸ“± Responsive design
- ğŸ¨ Modern animations
- ğŸ’¬ Message history
- ğŸ” Expandable details

---

## ğŸ”§ API Endpoints

### Backend API

```bash
GET  /                  # API info
GET  /health            # System status
POST /build-graph       # Build knowledge graph
POST /chat              # Query AI agent
GET  /stats             # Graph statistics
```

### Example Requests

**Build Graph:**
```bash
curl -X POST http://localhost:8000/build-graph \
  -H "Content-Type: application/json" \
  -d '{
    "connection_string": "postgresql://user:pass@host:port/db"
  }'
```

**Chat:**
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How many customers do we have?",
    "stream": false
  }'
```

---

## ğŸ§ª Testing Checklist

### Local Testing
- [ ] Neo4j running on port 7687
- [ ] Backend running on port 8000
- [ ] Frontend running on port 3000
- [ ] Can access frontend UI
- [ ] Build Graph tab loads
- [ ] Can enter connection string
- [ ] Graph builds successfully
- [ ] Chat tab loads
- [ ] Can send queries
- [ ] Receives AI responses
- [ ] Tools tracking works
- [ ] Reasoning chain visible

### Deployment Testing
- [ ] Backend deployed on Render
- [ ] Backend health endpoint responds
- [ ] Frontend deployed on Vercel
- [ ] Frontend can reach backend
- [ ] CORS working correctly
- [ ] Build graph works in production
- [ ] Chat works in production
- [ ] HTTPS working

---

## ğŸ’¡ Example Queries

### Simple Queries
```
How many customers do we have?
How many products are there?
Show me the graph statistics
```

### Semantic Search
```
Find products related to wireless audio
Show me electronic products
Products similar to smartphones
```

### Relationship Queries
```
What products has customer Aisha Khan ordered?
Which customers bought Smartphone Model X?
What products are in the Electronics category?
```

### Complex Queries
```
Which customers have bought products from the Electronics category?
Show me customers who have placed more than one order
What is the total value of all orders?
```

---

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI**: Web framework
- **Neo4j**: Graph database
- **FAISS**: Vector search
- **Gemini LLM**: AI model
- **LangGraph**: Agent framework
- **Sentence Transformers**: Embeddings

### Frontend
- **React 18**: UI framework
- **TypeScript**: Type safety
- **Axios**: API client
- **React Markdown**: Response formatting
- **CSS3**: Modern styling

### Deployment
- **Render**: Backend hosting
- **Vercel**: Frontend hosting
- **Docker**: Containerization
- **GitHub**: Version control

---

## ğŸ“Š System Flow

```
1. User enters PostgreSQL connection string
        â†“
2. Backend extracts schema
        â†“
3. Gemini LLM generates ontology
        â†“
4. Neo4j graph created
        â†“
5. FAISS vector index built
        â†“
6. User queries via chat
        â†“
7. AI agent selects tools:
   - vector_search (semantic)
   - cypher_query (graph)
   - filter_nodes (exact)
        â†“
8. Results displayed with reasoning
```

---

## ğŸ› Troubleshooting

### "Backend not responding"
```bash
# Check if backend is running
curl http://localhost:8000/health

# Restart backend
python3 rag_api_server.py
```

### "Neo4j connection failed"
```bash
# Check Neo4j
docker ps | grep neo4j

# Restart Neo4j
docker restart neo4j
```

### "CORS error"
```bash
# Backend CORS is already configured
# Check frontend .env has correct API URL
cat frontend/.env
```

### "Graph not building"
```bash
# Check logs
tail -f server.log

# Verify connection string format
postgresql://user:password@host:port/database
```

---

## ğŸ“š Documentation

- [README.md](./README.md) - Quick start
- [DEPLOYMENT.md](./DEPLOYMENT.md) - Deployment guide
- [frontend/README.md](./frontend/README.md) - Frontend docs
- [QUICK_START.md](./QUICK_START.md) - Quick commands

---

## ğŸ‰ Success!

Your RAG Knowledge Graph system is ready!

- âœ… PostgreSQL â†’ Knowledge Graph conversion
- âœ… AI-powered querying with Gemini LLM
- âœ… Semantic search with FAISS
- âœ… Modern dark-themed UI
- âœ… Real-time status updates
- âœ… Production-ready deployment

**Repository**: https://github.com/ydyazeed/RelationalDB-To-GraphRAG

Happy coding! ğŸš€

